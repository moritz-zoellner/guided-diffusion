#!/bin/sh
#SBATCH -J rollout_baseDP
#SBATCH -A rpaleja
#SBATCH -p a100-40gb
#SBATCH --cpus-per-task=8
#SBATCH --gpus-per-node=1
#SBATCH --mem=32G
#SBATCH --qos=normal
#SBATCH -t 24:00:00
#SBATCH -o slurm-%j.out

module load conda
#conda activate /scratch/gilbreth/zoellner/conda/envs/guided_diffusion
conda activate guided_diffusion

export MUJOCO_GL=egl
export EGL_DEVICE_ID=0
export CUDA_VISIBLE_DEVICES=0
unset DISPLAY

echo "Starting base rollout training via SLURM"
cd ~/src/guided-diffusion
python -u experiments/rollout_base_policy.py \
  --n_rollouts 40 \
  --output_path /scratch/gilbreth/zoellner/diffusion_rollouts/sr_rollout \
  --ckpt_path /scratch/gilbreth/zoellner/diffusion_runs/run_20260122_211123/20260122211129/models/model_epoch_1100_low_dim_v15_success_0.7.pth \
  --n_step_rollout_video 1 \
  --horizon 500
echo "Finished base rollout?" 